{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4929fc",
   "metadata": {},
   "source": [
    "# Citation Preference Estimation and Bootstrap Analysis\n",
    "\n",
    "This notebook computes the country–country citation preference measures used in the [paper](https://arxiv.org/abs/2404.05861), including the bootstrap-based estimates of over- and under-recognition.\n",
    "\n",
    "It requires the processed outputs generated by the data preparation notebook **1_GlobalCitationNetwork_dataprep**, in particular:\n",
    "\n",
    "- `oa_countrycites_nosameorg.csv.gz` — country-level citation counts with author- and affiliation-level self-citations removed  \n",
    "- `pub2journal.csv.gz` — publication-to-journal mappings from OpenAlex\n",
    "\n",
    "Both files must be available locally before running this notebook. If these inputs are not present, please first run **1_GlobalCitationNetwork_dataprep** or download the archived processed data provided in the shared data folder.\n",
    "\n",
    "The outputs of this notebook are used directly in the subsequent analysis and figure-generation steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a333e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyscisci.all as pyscisci\n",
    "\n",
    "# set this path to where the OpenAlex database is stored\n",
    "path2openalex = '/Users/hgt6rn/Documents/DataSets/OpenAlex'\n",
    "\n",
    "path2countrydata = \"/Users/hgt6rn/Documents/DataSets/OpenAlex/precomputed_metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the traditional citation preference measure\n",
    "\n",
    "dataset = \"oa_countrycites_nosameorg\"  # other data processing pipelines make: \"oa_countrycites\", \"oa_countrycites_noself\"\n",
    "\n",
    "\n",
    "countrycites = pd.read_csv(os.path.join(path2countrydata, dataset + \".csv.gz\"))\n",
    "\n",
    "country_auc_df = []\n",
    "def country_auc(citedf):\n",
    "    for cited_c in citedf['Country'].unique():\n",
    "        x = citedf[citedf['Country'] == cited_c]['CountryCitations'].values\n",
    "        y = citedf[citedf['Country'] != cited_c]['CountryCitations'].values\n",
    "        auc, delongcov = pyscisci.fast_delong(x, y)\n",
    "        cname, y = citedf.name\n",
    "        country_auc_df.append([cname, y, cited_c, auc, delongcov, x.shape[0]])\n",
    "\n",
    "countrycites.groupby(['CitingCountry', 'CitedYear'])[['Country', 'CountryCitations']].apply(country_auc)\n",
    "country_auc_df = pd.DataFrame(country_auc_df, columns=['CitingCountry', 'CitedYear', 'CitedCountry', 'AUC', 'Cov', 'N'])\n",
    "\n",
    "country_auc_df.to_csv(os.path.join(path2countrydata, dataset + '_auc.csv.gz'), compression='gzip', \n",
    "                                       index=False, header=True, mode='w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the journal information for bootstrap\n",
    "pub2journal = os.path.join(path2oa, \"pub2journal.csv.gz\")\n",
    "pub2journal.rename(columns={'PublicationId':'CitedPublicationId', 'JournalId':'CitedJournalId'}, inplace=True)\n",
    "\n",
    "countrycites = countrycites.merge(pub2journal, how='inner', on='CitedPublicationId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15644fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the journal bootstrap AUC\n",
    "\n",
    "def country_journal_auc_year(citedf, cname, y):\n",
    "    \n",
    "    baseline_df = citedf.drop_duplicates(subset=['CitedPublicationId']).reset_index(drop = True)\n",
    "    \n",
    "    for cited_c in citedf['Country'].unique():\n",
    "        \n",
    "        focus_c_df = citedf[citedf['Country'] == cited_c]\n",
    "        \n",
    "        xs = focus_c_df['CountryCitations'].values\n",
    "        \n",
    "        if xs.shape[0] >=50:\n",
    "            \n",
    "            baseline_df['sample_count'] = np.nan\n",
    "            journal_counts = focus_c_df['CitedJournalId'].value_counts()\n",
    "            baseline_df['sample_count'] = baseline_df['CitedJournalId'].map(journal_counts)\n",
    "            sampled_df = baseline_df.dropna(subset=['sample_count'])\n",
    "            \n",
    "            for isample in range(nsamples):\n",
    "                sampled_df = sampled_df.sample(frac=1)\n",
    "                sampled_df['cum_count'] = sampled_df.groupby('CitedJournalId', sort=False).cumcount()\n",
    "        \n",
    "                ys = sampled_df[sampled_df['cum_count'] < sampled_df['sample_count']]['CountryCitations'].values\n",
    "\n",
    "                auc = pyscisci.fast_auc(xs,ys)\n",
    "                \n",
    "                country_auc_df_year.append([cname, y, cited_c, auc, xs.shape[0], isample])\n",
    "\n",
    "\n",
    "nsamples=100\n",
    "country_auc_df_sample = []\n",
    "for focus_year in range(1990,2018):\n",
    "\n",
    "    countrycites_year = countrycites[countrycites['CitedYear'] == focus_year]\n",
    "\n",
    "    country_auc_df_year = []\n",
    "\n",
    "    for citing_c in countrycites_year['CitingCountry'].unique():\n",
    "        country_auc_year(countrycites_year[countrycites_year['CitingCountry'] == citing_c], cname=citing_c, y=focus_year)\n",
    "        print(citing_c)\n",
    "\n",
    "    \n",
    "    aucdf = pd.DataFrame(country_auc_df_year, columns=['CitingCountry', 'CitedYear', 'CitedCountry', 'AUC',  'N', 'isample'])\n",
    "    country_auc_df_sample.append(aucdf)\n",
    "\n",
    "\n",
    "country_auc_df_sample = pd.concat(country_auc_df_sample)\n",
    "country_auc_df = country_auc_df_sample.groupby(['CitingCountry', 'CitedYear', 'CitedCountry', 'N'], as_index=False)['AUC'].var()\n",
    "country_auc_df.rename(columns={'AUC':'Cov'},inplace=True)\n",
    "country_auc_df = country_auc_df.merge(country_auc_df_sample.groupby(['CitingCountry', 'CitedYear', 'CitedCountry', 'N'], as_index=False)['AUC'].mean(),\n",
    "how='left', on = ['CitingCountry', 'CitedYear', 'CitedCountry'])\n",
    "\n",
    "country_auc_df.to_csv(os.path.join(path2countrydata, 'nationalcitation_bootstrap_u100.csv.gz', \n",
    "                 compression='gzip', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
